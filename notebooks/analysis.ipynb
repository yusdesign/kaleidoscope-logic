{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Kaleidoscope Logic Analysis Notebook\n",
    "\n",
    "Statistical and analytical exploration of kaleidoscope sequences.\n",
    "\n",
    "## Analysis Tools\n",
    "1. Phase statistics and distributions\n",
    "2. Pattern complexity metrics\n",
    "3. Fourier analysis of sequences\n",
    "4. Correlation studies\n",
    "5. Machine learning analysis\n",
    "\n",
    "## Requirements\n",
    "```bash\n",
    "pip install numpy pandas matplotlib seaborn scipy scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats, fft\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Analysis libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load sequence data\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_sequence_data(sequence_name='main'):\n",
    "    \"\"\"Load sequence metadata and calculate statistics\"\"\"\n",
    "    \n",
    "    metadata_path = f\"../outputs/metadata/{sequence_name}_metadata.json\"\n",
    "    \n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(metadata['frames_data'])\n",
    "        \n",
    "        print(f\"üìä Loaded {sequence_name} sequence: {len(df)} frames\")\n",
    "        print(f\"  Phase range: {df['phase_diff'].min():.3f} - {df['phase_diff'].max():.3f} rad\")\n",
    "        print(f\"  ŒîŒ∏ per frame: {metadata.get('delta_left', 'N/A')} (L), {metadata.get('delta_right', 'N/A')} (R)\")\n",
    "        \n",
    "        return df, metadata\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Metadata not found: {metadata_path}\")\n",
    "        print(\"Generating synthetic data for analysis...\")\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        frames = 25\n",
    "        delta_left = 0.08\n",
    "        delta_right = 0.095\n",
    "        \n",
    "        data = []\n",
    "        left_phase = 0.0\n",
    "        right_phase = 0.39\n",
    "        \n",
    "        for i in range(frames):\n",
    "            data.append({\n",
    "                'frame': i,\n",
    "                'left_angle': left_phase,\n",
    "                'right_angle': right_phase,\n",
    "                'phase_diff': right_phase - left_phase\n",
    "            })\n",
    "            left_phase = (left_phase + delta_left) % (2*np.pi)\n",
    "            right_phase = (right_phase + delta_right) % (2*np.pi)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        metadata = {\n",
    "            'sequence_name': sequence_name + '_synthetic',\n",
    "            'frames': frames,\n",
    "            'delta_left': delta_left,\n",
    "            'delta_right': delta_right\n",
    "        }\n",
    "        \n",
    "        return df, metadata\n",
    "\n",
    "# Load main sequence\n",
    "df_main, meta_main = load_sequence_data('main')\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Comprehensive statistical analysis\n",
    "def analyze_sequence_statistics(df):\n",
    "    \"\"\"Perform comprehensive statistical analysis\"\"\"\n",
    "    \n",
    "    print(\"üìà SEQUENCE STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(f\"  Total frames: {len(df)}\")\n",
    "    print(f\"  Left phase range: {df['left_angle'].min():.3f} - {df['left_angle'].max():.3f} rad\")\n",
    "    print(f\"  Right phase range: {df['right_angle'].min():.3f} - {df['right_angle'].max():.3f} rad\")\n",
    "    print(f\"  Phase difference range: {df['phase_diff'].min():.3f} - {df['phase_diff'].max():.3f} rad\")\n",
    "    \n",
    "    # Central tendencies\n",
    "    print(\"\\nCentral Tendencies:\")\n",
    "    print(f\"  Mean phase diff: {df['phase_diff'].mean():.3f} rad\")\n",
    "    print(f\"  Median phase diff: {df['phase_diff'].median():.3f} rad\")\n",
    "    print(f\"  Mode phase diff: {stats.mode(df['phase_diff']).mode[0]:.3f} rad\")\n",
    "    \n",
    "    # Dispersion\n",
    "    print(\"\\nDispersion Measures:\")\n",
    "    print(f\"  Std deviation: {df['phase_diff'].std():.3f} rad\")\n",
    "    print(f\"  Variance: {df['phase_diff'].var():.3f} rad¬≤\")\n",
    "    print(f\"  Range: {df['phase_diff'].max() - df['phase_diff'].min():.3f} rad\")\n",
    "    print(f\"  IQR: {df['phase_diff'].quantile(0.75) - df['phase_diff'].quantile(0.25):.3f} rad\")\n",
    "    \n",
    "    # Shape\n",
    "    print(\"\\nDistribution Shape:\")\n",
    "    print(f\"  Skewness: {df['phase_diff'].skew():.3f}\")\n",
    "    print(f\"  Kurtosis: {df['phase_diff'].kurtosis():.3f}\")\n",
    "    \n",
    "    # Hypothesis testing\n",
    "    print(\"\\nHypothesis Tests:\")\n",
    "    \n",
    "    # Test for linear trend\n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df['frame'], df['phase_diff'])\n",
    "    print(f\"  Linear trend test: r = {r_value:.3f}, p = {p_value:.3e}\")\n",
    "    \n",
    "    # Test for normality\n",
    "    from scipy.stats import shapiro\n",
    "    stat, p = shapiro(df['phase_diff'])\n",
    "    print(f\"  Normality test (Shapiro-Wilk): W = {stat:.3f}, p = {p:.3e}\")\n",
    "    \n",
    "    # Test for stationarity (simplified)\n",
    "    from scipy.stats import kendalltau\n",
    "    tau, p_tau = kendalltau(df['frame'], df['phase_diff'])\n",
    "    print(f\"  Stationarity test (Kendall's tau): œÑ = {tau:.3f}, p = {p_tau:.3e}\")\n",
    "    \n",
    "    return {\n",
    "        'basic': {\n",
    "            'frames': len(df),\n",
    "            'phase_range': (df['phase_diff'].min(), df['phase_diff'].max())\n",
    "        },\n",
    "        'central': {\n",
    "            'mean': df['phase_diff'].mean(),\n",
    "            'median': df['phase_diff'].median(),\n",
    "            'std': df['phase_diff'].std()\n",
    "        },\n",
    "        'tests': {\n",
    "            'linear_r': r_value,\n",
    "            'linear_p': p_value,\n",
    "            'normality_p': p,\n",
    "            'stationarity_tau': tau\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run analysis\n",
    "stats_results = analyze_sequence_statistics(df_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create comprehensive statistical visualizations\n",
    "def create_statistical_visualizations(df, sequence_name='main'):\n",
    "    \"\"\"Create all statistical visualizations\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Distribution histogram with KDE\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    sns.histplot(df['phase_diff'], kde=True, ax=ax1, color='skyblue', edgecolor='black')\n",
    "    ax1.axvline(df['phase_diff'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"phase_diff\"].mean():.3f}')\n",
    "    ax1.axvline(df['phase_diff'].median(), color='green', linestyle='--', label=f'Median: {df[\"phase_diff\"].median():.3f}')\n",
    "    ax1.set_xlabel('Phase Difference ŒîŒ∏ (rad)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Phase Differences')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Box plot\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    sns.boxplot(y=df['phase_diff'], ax=ax2, color='lightgreen')\n",
    "    ax2.set_ylabel('Phase Difference ŒîŒ∏ (rad)')\n",
    "    ax2.set_title('Box Plot of Phase Differences')\n",
    "    \n",
    "    # 3. QQ plot for normality\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    stats.probplot(df['phase_diff'], dist=\"norm\", plot=ax3)\n",
    "    ax3.set_title('Q-Q Plot for Normality')\n",
    "    \n",
    "    # 4. Time series decomposition\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    ax4.plot(df['frame'], df['phase_diff'], 'b-', linewidth=2, label='Phase Difference')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df['frame'], df['phase_diff'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax4.plot(df['frame'], p(df['frame']), 'r--', linewidth=2, label=f'Trend: {z[0]:.3f}x + {z[1]:.3f}')\n",
    "    \n",
    "    ax4.set_xlabel('Frame')\n",
    "    ax4.set_ylabel('ŒîŒ∏ (rad)')\n",
    "    ax4.set_title('Time Series with Linear Trend')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Autocorrelation\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    from pandas.plotting import autocorrelation_plot\n",
    "    autocorrelation_plot(df['phase_diff'], ax=ax5)\n",
    "    ax5.set_title('Autocorrelation Function')\n",
    "    \n",
    "    # 6. Correlation heatmap\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    correlation = df[['left_angle', 'right_angle', 'phase_diff']].corr()\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, ax=ax6, square=True)\n",
    "    ax6.set_title('Correlation Matrix')\n",
    "    \n",
    "    # 7. Phase space with density\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    scatter = ax7.scatter(df['left_angle'], df['right_angle'], \n",
    "                         c=df['frame'], cmap='viridis', s=50, alpha=0.7)\n",
    "    ax7.plot(df['left_angle'], df['right_angle'], 'gray', alpha=0.3, linewidth=1)\n",
    "    ax7.set_xlabel('Left Phase Œ∏L (rad)')\n",
    "    ax7.set_ylabel('Right Phase Œ∏R (rad)')\n",
    "    ax7.set_title('Phase Space with Frame Coloring')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax7, label='Frame')\n",
    "    \n",
    "    # 8. Rolling statistics\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    window = min(5, len(df) // 4)\n",
    "    rolling_mean = df['phase_diff'].rolling(window=window).mean()\n",
    "    rolling_std = df['phase_diff'].rolling(window=window).std()\n",
    "    \n",
    "    ax8.plot(df['frame'], df['phase_diff'], 'b-', alpha=0.3, label='Original')\n",
    "    ax8.plot(df['frame'], rolling_mean, 'r-', linewidth=2, label=f'Rolling Mean (w={window})')\n",
    "    ax8.fill_between(df['frame'], \n",
    "                     rolling_mean - rolling_std, \n",
    "                     rolling_mean + rolling_std, \n",
    "                     alpha=0.2, color='red', label='Rolling Std')\n",
    "    \n",
    "    ax8.set_xlabel('Frame')\n",
    "    ax8.set_ylabel('ŒîŒ∏ (rad)')\n",
    "    ax8.set_title('Rolling Statistics')\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Statistical summary\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    ax9.axis('off')\n",
    "    \n",
    "    stats_text = (\n",
    "        f\"STATISTICAL SUMMARY\\n\"\n",
    "        f\"Sequence: {sequence_name}\\n\"\n",
    "        f\"Frames: {len(df)}\\n\"\n",
    "        f\"\\n\"\n",
    "        f\"Phase Difference ŒîŒ∏\\n\"\n",
    "        f\"Mean: {df['phase_diff'].mean():.3f}\\n\"\n",
    "        f\"Std: {df['phase_diff'].std():.3f}\\n\"\n",
    "        f\"Min: {df['phase_diff'].min():.3f}\\n\"\n",
    "        f\"Max: {df['phase_diff'].max():.3f}\\n\"\n",
    "        f\"\\n\"\n",
    "        f\"Trend Analysis\\n\"\n",
    "        f\"Slope: {stats_results['tests']['linear_r']:.3f}\\n\"\n",
    "        f\"p-value: {stats_results['tests']['linear_p']:.3e}\\n\"\n",
    "        f\"Normality: {stats_results['tests']['normality_p']:.3e}\"\n",
    "    )\n",
    "    \n",
    "    ax9.text(0.1, 0.95, stats_text, transform=ax9.transAxes,\n",
    "             fontsize=9, fontfamily='monospace',\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'Comprehensive Statistical Analysis: {sequence_name.upper()} Sequence', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "create_statistical_visualizations(df_main, 'main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fourier and Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Fourier and spectral analysis\n",
    "def analyze_spectral_properties(df):\n",
    "    \"\"\"Perform Fourier and spectral analysis\"\"\"\n",
    "    \n",
    "    signal = df['phase_diff'].values\n",
    "    N = len(signal)\n",
    "    T = 1.0  # Sampling interval (1 frame)\n",
    "    \n",
    "    # Compute FFT\n",
    "    yf = fft.fft(signal)\n",
    "    xf = fft.fftfreq(N, T)[:N//2]\n",
    "    \n",
    "    # Power spectrum\n",
    "    power_spectrum = 2.0/N * np.abs(yf[0:N//2])\n",
    "    \n",
    "    # Find dominant frequencies\n",
    "    dominant_idx = np.argmax(power_spectrum[1:]) + 1  # Skip DC component\n",
    "    dominant_freq = xf[dominant_idx]\n",
    "    dominant_power = power_spectrum[dominant_idx]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # 1. Original signal\n",
    "    axes[0, 0].plot(df['frame'], signal, 'b-', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Frame')\n",
    "    axes[0, 0].set_ylabel('Phase Difference ŒîŒ∏')\n",
    "    axes[0, 0].set_title('Original Signal')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Power spectrum\n",
    "    axes[0, 1].plot(xf[1:], power_spectrum[1:], 'r-', linewidth=2)\n",
    "    axes[0, 1].axvline(dominant_freq, color='green', linestyle='--', \n",
    "                      label=f'Dominant: {dominant_freq:.3f} frame‚Åª¬π')\n",
    "    axes[0, 1].set_xlabel('Frequency (frame‚Åª¬π)')\n",
    "    axes[0, 1].set_ylabel('Power')\n",
    "    axes[0, 1].set_title('Power Spectrum')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Spectrogram\n",
    "    from scipy.signal import spectrogram\n",
    "    f, t, Sxx = spectrogram(signal, fs=1.0, nperseg=min(8, N//2))\n",
    "    im = axes[1, 0].pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "    axes[1, 0].set_xlabel('Frame')\n",
    "    axes[1, 0].set_ylabel('Frequency (frame‚Åª¬π)')\n",
    "    axes[1, 0].set_title('Spectrogram')\n",
    "    plt.colorbar(im, ax=axes[1, 0], label='Power (dB)')\n",
    "    \n",
    "    # 4. Cumulative periodogram\n",
    "    axes[1, 1].plot(xf[1:], np.cumsum(power_spectrum[1:]), 'purple', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Frequency (frame‚Åª¬π)')\n",
    "    axes[1, 1].set_ylabel('Cumulative Power')\n",
    "    axes[1, 1].set_title('Cumulative Periodogram')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Spectral Analysis of Phase Evolution', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üì° SPECTRAL ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Signal length: {N} frames\")\n",
    "    print(f\"Sampling frequency: {1/T} frame‚Åª¬π\")\n",
    "    print(f\"Nyquist frequency: {0.5/T} frame‚Åª¬π\")\n",
    "    print(f\"Dominant frequency: {dominant_freq:.3f} frame‚Åª¬π\")\n",
    "    print(f\"Dominant period: {1/dominant_freq:.1f} frames\" if dominant_freq > 0 else \"No dominant frequency\")\n",
    "    print(f\"Total power: {np.sum(power_spectrum):.3f}\")\n",
    "    print(f\"Power in dominant frequency: {dominant_power:.3f} ({dominant_power/np.sum(power_spectrum)*100:.1f}% of total)\")\n",
    "    \n",
    "    return {\n",
    "        'dominant_frequency': dominant_freq,\n",
    "        'dominant_power': dominant_power,\n",
    "        'total_power': np.sum(power_spectrum),\n",
    "        'power_spectrum': power_spectrum,\n",
    "        'frequencies': xf\n",
    "    }\n",
    "\n",
    "# Run spectral analysis\n",
    "spectral_results = analyze_spectral_properties(df_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Machine learning analysis\n",
    "def analyze_with_ml(df):\n",
    "    \"\"\"Apply machine learning techniques\"\"\"\n",
    "    \n",
    "    try:\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "        from sklearn.cluster import KMeans, DBSCAN\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        \n",
    "        print(\"ü§ñ Applying Machine Learning Analysis...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        X = df[['left_angle', 'right_angle', 'phase_diff']].values\n",
    "        \n",
    "        # Standardize\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "        \n",
    "        # 1. PCA visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        axes[0, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=df['frame'], cmap='viridis', s=50, alpha=0.7)\n",
    "        axes[0, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "        axes[0, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "        axes[0, 0].set_title('PCA of Phase Space')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. K-means clustering\n",
    "        kmeans = KMeans(n_clusters=min(4, len(df)//3), random_state=42)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        axes[0, 1].scatter(df['left_angle'], df['right_angle'], c=clusters, cmap='tab10', s=50, alpha=0.7)\n",
    "        axes[0, 1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                          marker='X', s=200, c='red', label='Centroids')\n",
    "        axes[0, 1].set_xlabel('Left Phase Œ∏L')\n",
    "        axes[0, 1].set_ylabel('Right Phase Œ∏R')\n",
    "        axes[0, 1].set_title(f'K-means Clustering (k={kmeans.n_clusters})')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Anomaly detection\n",
    "        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "        anomalies = iso_forest.fit_predict(X_scaled)\n",
    "        \n",
    "        colors = ['blue' if a == 1 else 'red' for a in anomalies]\n",
    "        axes[0, 2].scatter(df['frame'], df['phase_diff'], c=colors, s=50, alpha=0.7)\n",
    "        axes[0, 2].set_xlabel('Frame')\n",
    "        axes[0, 2].set_ylabel('Phase Difference ŒîŒ∏')\n",
    "        axes[0, 2].set_title('Anomaly Detection (Isolation Forest)')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Silhouette analysis\n",
    "        silhouette_scores = []\n",
    "        k_range = range(2, min(8, len(df)//2))\n",
    "        \n",
    "        for k in k_range:\n",
    "            kmeans_temp = KMeans(n_clusters=k, random_state=42)\n",
    "            clusters_temp = kmeans_temp.fit_predict(X_scaled)\n",
    "            if len(np.unique(clusters_temp)) > 1:\n",
    "                score = silhouette_score(X_scaled, clusters_temp)\n",
    "                silhouette_scores.append(score)\n",
    "            else:\n",
    "                silhouette_scores.append(0)\n",
    "        \n",
    "        axes[1, 0].plot(list(k_range), silhouette_scores, 'o-', linewidth=2)\n",
    "        axes[1, 0].set_xlabel('Number of clusters (k)')\n",
    "        axes[1, 0].set_ylabel('Silhouette Score')\n",
    "        axes[1, 0].set_title('Silhouette Analysis')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Feature importance\n",
    "        feature_names = ['Left Œ∏', 'Right Œ∏', 'ŒîŒ∏']\n",
    "        feature_importance = np.abs(pca.components_[0])  # Use first PC loadings\n",
    "        \n",
    "        axes[1, 1].bar(feature_names, feature_importance, color='skyblue', edgecolor='black')\n",
    "        axes[1, 1].set_ylabel('Importance (PC1 loadings)')\n",
    "        axes[1, 1].set_title('Feature Importance')\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 6. ML summary\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        ml_text = (\n",
    "            f\"MACHINE LEARNING SUMMARY\\n\"\n",
    "            f\"Samples: {len(df)}\\n\"\n",
    "            f\"Features: 3\\n\"\n",
    "            f\"\\n\"\n",
    "            f\"PCA Results\\n\"\n",
    "            f\"Variance explained: {pca.explained_variance_ratio_.sum()*100:.1f}%\\n\"\n",
    "            f\"PC1: {pca.explained_variance_ratio_[0]*100:.1f}%\\n\"\n",
    "            f\"PC2: {pca.explained_variance_ratio_[1]*100:.1f}%\\n\"\n",
    "            f\"\\n\"\n",
    "            f\"Clustering\\n\"\n",
    "            f\"Optimal clusters: {list(k_range)[np.argmax(silhouette_scores)]}\\n\"\n",
    "            f\"Best silhouette: {max(silhouette_scores):.3f}\\n\"\n",
    "            f\"\\n\"\n",
    "            f\"Anomalies: {(anomalies == -1).sum()} ({((anomalies == -1).sum()/len(df))*100:.1f}%)\"\n",
    "        )\n",
    "        \n",
    "        axes[1, 2].text(0.1, 0.95, ml_text, transform=axes[1, 2].transAxes,\n",
    "                       fontsize=9, fontfamily='monospace',\n",
    "                       verticalalignment='top',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightblue', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Machine Learning Analysis of Kaleidoscope Sequences', \n",
    "                     fontsize=14, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Machine learning analysis complete!\")\n",
    "        \n",
    "        return {\n",
    "            'pca_variance': pca.explained_variance_ratio_,\n",
    "            'optimal_clusters': list(k_range)[np.argmax(silhouette_scores)],\n",
    "            'silhouette_score': max(silhouette_scores),\n",
    "            'anomaly_count': (anomalies == -1).sum()\n",
    "        }\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ö†Ô∏è  scikit-learn not installed: {e}\")\n",
    "        print(\"Install with: pip install scikit-learn\")\n",
    "        return None\n",
    "\n",
    "# Run ML analysis\n",
    "ml_results = analyze_with_ml(df_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Export analysis results\n",
    "def export_analysis_results(df, stats_results, spectral_results, ml_results, filename='analysis_results.json'):\n",
    "    \"\"\"Export all analysis results to JSON\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'metadata': {\n",
    "            'sequence_name': 'main',\n",
    "            'frames': len(df),\n",
    "            'analysis_date': pd.Timestamp.now().isoformat(),\n",
    "            'analysis_type': 'comprehensive'\n",
    "        },\n",
    "        'statistics': stats_results,\n",
    "        'spectral_analysis': {\n",
    "            'dominant_frequency': float(spectral_results['dominant_frequency']),\n",
    "            'dominant_power': float(spectral_results['dominant_power']),\n",
    "            'total_power': float(spectral_results['total_power'])\n",
    "        },\n",
    "        'machine_learning': ml_results if ml_results else 'Not available',\n",
    "        'raw_data_summary': {\n",
    "            'left_phase_stats': {\n",
    "                'mean': float(df['left_angle'].mean()),\n",
    "                'std': float(df['left_angle'].std()),\n",
    "                'min': float(df['left_angle'].min()),\n",
    "                'max': float(df['left_angle'].max())\n",
    "            },\n",
    "            'phase_diff_stats': {\n",
    "                'mean': float(df['phase_diff'].mean()),\n",
    "                'std': float(df['phase_diff'].std()),\n",
    "                'min': float(df['phase_diff'].min()),\n",
    "                'max': float(df['phase_diff'].max()),\n",
    "                'trend_slope': float(np.polyfit(df['frame'], df['phase_diff'], 1)[0])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    # Also save to CSV\n",
    "    csv_filename = filename.replace('.json', '.csv')\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Analysis results exported:\")\n",
    "    print(f\"   JSON: {filename}\")\n",
    "    print(f\"   CSV: {csv_filename}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nüìä ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Sequence: main ({len(df)} frames)\")\n",
    "    print(f\"Phase difference: {df['phase_diff'].mean():.3f} ¬± {df['phase_diff'].std():.3f} rad\")\n",
    "    print(f\"Trend slope: {np.polyfit(df['frame'], df['phase_diff'], 1)[0]:.3e} rad/frame\")\n",
    "    if spectral_results:\n",
    "        print(f\"Dominant frequency: {spectral_results['dominant_frequency']:.3f} frame‚Åª¬π\")\n",
    "    if ml_results:\n",
    "        print(f\"Optimal clusters: {ml_results['optimal_clusters']}\")\n",
    "        print(f\"Silhouette score: {ml_results['silhouette_score']:.3f}\")\n",
    "\n",
    "# Export results\n",
    "export_analysis_results(df_main, stats_results, spectral_results, ml_results, \n",
    "                       filename='../outputs/analysis/main_analysis_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis Complete!\n",
    "\n",
    "This notebook has performed:\n",
    "\n",
    "1. **Statistical analysis** of phase distributions\n",
    "2. **Spectral analysis** with Fourier transforms\n",
    "3. **Machine learning** clustering and anomaly detection\n",
    "4. **Comprehensive visualization** of all results\n",
    "5. **Data export** for further analysis\n",
    "\n",
    "To analyze different sequences:\n",
    "```python\n",
    "df, meta = load_sequence_data('rotation')  # or 'quick'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 
